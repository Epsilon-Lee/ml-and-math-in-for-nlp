# ml-and-math-in-for-nlp
An evolving notes on machine learning and mathematical techniques in and for Natural Language Processing.



## Collection of papers by topic

### Latent Variable Model and its Solution

- [Learning Opinion Summarizers by Selecting Informative Reviews](https://arxiv.org/pdf/2109.04325.pdf), Ivan Titov's group. `REINFORCE` `amortized varitional inference`
- [Sequence-to-Sequence Learning with Latent Neural Grammars](https://arxiv.org/abs/2109.01135), Yoon Kim. `likelihood bounding`
- [Structured Reordering for Modeling Latent Alignments in Sequence Transduction](https://arxiv.org/abs/2106.03257), Ivan Titov's group. `marginalization`



### Sampling and Search Techniques

- [Determinantal Beam Search](https://arxiv.org/abs/2106.07400), Ryan Cotterell's group. `beam search`
- [Mode recovery in neural autoregressive sequence modeling](https://aclanthology.org/2021.spnlp-1.5.pdf), Kyunghyun Cho's group. `sampling`
- [Parallel and Flexible Sampling from Autoregressive Models via Langevin Dynamics]()



### Information Theory

- [What Context Features Can Transformer Language Models Use?](https://arxiv.org/abs/2106.08367), Jacob Andreas's group. `V-information`
- [Conditional probing: measuring usable information beyond a baseline](https://arxiv.org/pdf/2109.09234.pdf), Percy Liang's group. `V-information`
- [On the Complexity and Typology of Inflectional Morphological Systems](https://arxiv.org/pdf/1807.02747.pdf), Ryan Cotterell. `complexity measure`



### Geometry

- [The Low-Dimensional Linear Geometry of Contextualized Word Representations](), Jacob Andreas's group.



### Discrete optimization

> submodular, Gumbel-Softmax



### Learning Paradigms

#### Reinforcement Learning

- [Learning Natural Language Generation from Scratch](https://arxiv.org/pdf/2109.09371.pdf), DeepMind.
